{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from propinf.training.models import AlexnetCNN, SimpleCNN\n",
    "from propinf.training.training_utils import fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "batch_size = 256"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    ")\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root=\"./data\", train=True, download=True, transform=transform\n",
    ")\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=batch_size, shuffle=True, num_workers=8\n",
    ")\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root=\"./data\", train=False, download=True, transform=transform\n",
    ")\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=batch_size, shuffle=False, num_workers=8\n",
    ")\n",
    "\n",
    "classes = (\n",
    "    \"plane\",\n",
    "    \"car\",\n",
    "    \"bird\",\n",
    "    \"cat\",\n",
    "    \"deer\",\n",
    "    \"dog\",\n",
    "    \"frog\",\n",
    "    \"horse\",\n",
    "    \"ship\",\n",
    "    \"truck\",\n",
    ")\n",
    "\n",
    "# # get some random training images\n",
    "# dataiter = iter(trainloader)\n",
    "# images, labels = next(dataiter)\n",
    "\n",
    "# # show images\n",
    "# imshow(torchvision.utils.make_grid(images))\n",
    "# # print labels\n",
    "# print(' '.join(f'{classes[labels[j]]:5s}' for j in range(batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loaders = {\"train\": trainloader, \"val\": testloader}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloaders, criterion, optimizer, num_epochs=25, device=\"cuda\"):\n",
    "    # Initialize variables to monitor training and validation loss\n",
    "    train_loss = []\n",
    "    val_loss = []\n",
    "    for epoch in range(num_epochs):\n",
    "        # Initialize variables to monitor training accuracy\n",
    "        train_acc = 0.0\n",
    "        val_acc = 0.0\n",
    "        # Set the model to train mode\n",
    "        model.train()\n",
    "        for i, (inputs, labels) in enumerate(dataloaders[\"train\"]):\n",
    "            # Move input and label tensors to the GPU\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # Update training accuracy\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            train_acc += torch.sum(preds == labels.data)\n",
    "        # Print training statistics for the epoch\n",
    "        train_loss.append(loss)\n",
    "        print(\n",
    "            \"Epoch: {}/{}, Training Loss: {:.4f}, Training Accuracy: {:.4f}\".format(\n",
    "                epoch + 1,\n",
    "                num_epochs,\n",
    "                loss.item(),\n",
    "                train_acc / len(dataloaders[\"train\"].dataset),\n",
    "            )\n",
    "        )\n",
    "        # Set the model to evaluate mode\n",
    "        model.eval()\n",
    "        for i, (inputs, labels) in enumerate(dataloaders[\"val\"]):\n",
    "            # Move input and label tensors to the GPU\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            # Update validation accuracy\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            val_acc += torch.sum(preds == labels.data)\n",
    "        val_loss.append(loss)\n",
    "        # Print validation statistics\n",
    "        print(\n",
    "            \"\\t\\tValidation Loss: {:.4f}, Validation Accuracy: {:.4f}\".format(\n",
    "                # epoch + 1,\n",
    "                # num_epochs,\n",
    "                loss.item(),\n",
    "                val_acc / len(dataloaders[\"val\"].dataset),\n",
    "            )\n",
    "        )\n",
    "    return train_loss, val_loss\n",
    "\n",
    "\n",
    "def evaluate_accuracy(model, dataloader, device):\n",
    "    model.eval()  # set the model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():  # temporarily set all the requires_grad flag to false\n",
    "        for data in dataloader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = correct / total\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = AlexnetCNN()\n",
    "model = SimpleCNN()\n",
    "model = model.train()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr = 0.001, weight_decay=5e-4,)\n",
    "criterion = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/35, Training Loss: 1.4088, Training Accuracy: 0.4254\n",
      "\t\tValidation Loss: 1.2181, Validation Accuracy: 0.5386\n",
      "Epoch: 2/35, Training Loss: 0.9450, Training Accuracy: 0.5652\n",
      "\t\tValidation Loss: 0.8416, Validation Accuracy: 0.6252\n",
      "Epoch: 3/35, Training Loss: 0.8201, Training Accuracy: 0.6395\n",
      "\t\tValidation Loss: 0.8000, Validation Accuracy: 0.6685\n",
      "Epoch: 4/35, Training Loss: 0.7803, Training Accuracy: 0.6833\n",
      "\t\tValidation Loss: 0.8747, Validation Accuracy: 0.6895\n",
      "Epoch: 5/35, Training Loss: 0.8084, Training Accuracy: 0.7141\n",
      "\t\tValidation Loss: 0.5293, Validation Accuracy: 0.7210\n",
      "Epoch: 6/35, Training Loss: 1.0032, Training Accuracy: 0.7392\n",
      "\t\tValidation Loss: 0.4488, Validation Accuracy: 0.7381\n",
      "Epoch: 7/35, Training Loss: 0.6486, Training Accuracy: 0.7561\n",
      "\t\tValidation Loss: 0.6480, Validation Accuracy: 0.7568\n",
      "Epoch: 8/35, Training Loss: 0.5342, Training Accuracy: 0.7738\n",
      "\t\tValidation Loss: 0.4679, Validation Accuracy: 0.7661\n",
      "Epoch: 9/35, Training Loss: 0.5796, Training Accuracy: 0.7864\n",
      "\t\tValidation Loss: 0.4441, Validation Accuracy: 0.7671\n",
      "Epoch: 10/35, Training Loss: 0.5048, Training Accuracy: 0.7957\n",
      "\t\tValidation Loss: 0.6691, Validation Accuracy: 0.7742\n",
      "Epoch: 11/35, Training Loss: 0.5772, Training Accuracy: 0.8111\n",
      "\t\tValidation Loss: 0.6314, Validation Accuracy: 0.7815\n",
      "Epoch: 12/35, Training Loss: 0.3124, Training Accuracy: 0.8174\n",
      "\t\tValidation Loss: 0.5189, Validation Accuracy: 0.7826\n",
      "Epoch: 13/35, Training Loss: 0.4998, Training Accuracy: 0.8318\n",
      "\t\tValidation Loss: 0.5092, Validation Accuracy: 0.7879\n",
      "Epoch: 14/35, Training Loss: 0.5214, Training Accuracy: 0.8393\n",
      "\t\tValidation Loss: 0.4069, Validation Accuracy: 0.7871\n",
      "Epoch: 15/35, Training Loss: 0.4626, Training Accuracy: 0.8476\n",
      "\t\tValidation Loss: 0.5294, Validation Accuracy: 0.7939\n",
      "Epoch: 16/35, Training Loss: 0.5320, Training Accuracy: 0.8522\n",
      "\t\tValidation Loss: 0.4266, Validation Accuracy: 0.7927\n",
      "Epoch: 17/35, Training Loss: 0.3981, Training Accuracy: 0.8582\n",
      "\t\tValidation Loss: 0.4581, Validation Accuracy: 0.7950\n",
      "Epoch: 18/35, Training Loss: 0.3228, Training Accuracy: 0.8648\n",
      "\t\tValidation Loss: 0.4686, Validation Accuracy: 0.7955\n",
      "Epoch: 19/35, Training Loss: 0.4141, Training Accuracy: 0.8729\n",
      "\t\tValidation Loss: 0.4684, Validation Accuracy: 0.7977\n",
      "Epoch: 20/35, Training Loss: 0.2149, Training Accuracy: 0.8781\n",
      "\t\tValidation Loss: 0.7773, Validation Accuracy: 0.8020\n",
      "Epoch: 21/35, Training Loss: 0.4271, Training Accuracy: 0.8822\n",
      "\t\tValidation Loss: 0.4138, Validation Accuracy: 0.7996\n",
      "Epoch: 22/35, Training Loss: 0.5516, Training Accuracy: 0.8887\n",
      "\t\tValidation Loss: 0.6036, Validation Accuracy: 0.8084\n",
      "Epoch: 23/35, Training Loss: 0.2981, Training Accuracy: 0.8904\n",
      "\t\tValidation Loss: 0.5327, Validation Accuracy: 0.7986\n",
      "Epoch: 24/35, Training Loss: 0.3519, Training Accuracy: 0.8936\n",
      "\t\tValidation Loss: 0.6004, Validation Accuracy: 0.8065\n",
      "Epoch: 25/35, Training Loss: 0.2798, Training Accuracy: 0.8982\n",
      "\t\tValidation Loss: 0.7003, Validation Accuracy: 0.7955\n",
      "Epoch: 26/35, Training Loss: 0.3727, Training Accuracy: 0.9012\n",
      "\t\tValidation Loss: 0.4808, Validation Accuracy: 0.8000\n",
      "Epoch: 27/35, Training Loss: 0.2645, Training Accuracy: 0.9086\n",
      "\t\tValidation Loss: 0.5553, Validation Accuracy: 0.7984\n",
      "Epoch: 28/35, Training Loss: 0.3231, Training Accuracy: 0.9105\n",
      "\t\tValidation Loss: 0.3221, Validation Accuracy: 0.8020\n",
      "Epoch: 29/35, Training Loss: 0.2368, Training Accuracy: 0.9112\n",
      "\t\tValidation Loss: 0.4450, Validation Accuracy: 0.7953\n",
      "Epoch: 30/35, Training Loss: 0.2667, Training Accuracy: 0.9143\n",
      "\t\tValidation Loss: 0.5872, Validation Accuracy: 0.8055\n",
      "Epoch: 31/35, Training Loss: 0.2802, Training Accuracy: 0.9135\n",
      "\t\tValidation Loss: 0.6125, Validation Accuracy: 0.7949\n",
      "Epoch: 32/35, Training Loss: 0.1570, Training Accuracy: 0.9163\n",
      "\t\tValidation Loss: 0.4537, Validation Accuracy: 0.8003\n",
      "Epoch: 33/35, Training Loss: 0.3261, Training Accuracy: 0.9203\n",
      "\t\tValidation Loss: 0.5984, Validation Accuracy: 0.8045\n",
      "Epoch: 34/35, Training Loss: 0.1658, Training Accuracy: 0.9220\n",
      "\t\tValidation Loss: 0.3175, Validation Accuracy: 0.7903\n",
      "Epoch: 35/35, Training Loss: 0.2925, Training Accuracy: 0.9225\n",
      "\t\tValidation Loss: 0.7417, Validation Accuracy: 0.8052\n",
      "CPU times: user 1min 3s, sys: 28.7 s, total: 1min 32s\n",
      "Wall time: 1min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_loss, val_loss = train(\n",
    "    model=model,\n",
    "    dataloaders=data_loaders,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    num_epochs=35,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy: 0.8052\n"
     ]
    }
   ],
   "source": [
    "model_acc = evaluate_accuracy(model, data_loaders[\"val\"], device)\n",
    "print(f\"Model accuracy: {model_acc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleCNN(\n",
       "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=2048, out_features=512, bias=True)\n",
       "  (fc2): Linear(in_features=512, out_features=10, bias=True)\n",
       "  (dropout): Dropout(p=0.25, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lemon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dedc6e9d36f5fe0ab4d9e7a27bf278c6ab614087e8708f25ce911079ab243912"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
